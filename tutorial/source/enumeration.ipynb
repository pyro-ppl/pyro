{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with discrete latent variables\n",
    "\n",
    "This tutorial describes Pyro's enumeration strategy for discrete latent variable models.\n",
    "First read the [Tensor Shapes Tutorial](http://pyro.ai/examples/tensor_shapes.html) and the [Gaussian Mixture Model Tutorial](http://pyro.ai/examples/gmm.html).\n",
    "\n",
    "#### Summary \n",
    "\n",
    "- Pyro implements automatic enumeration over discrete latent variables.\n",
    "- This strategy can be used alone or inside SVI (via [TraceEnum_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.TraceEnum_ELBO)), HMC, or NUTS.\n",
    "- Annotate a sample site `infer={\"enumerate\": \"parallel\"}` to trigger enumeration.\n",
    "- If a sample site determines downstream structure, instead use `{\"enumerate\": \"sequential\"}`.\n",
    "- Write your models to allow arbitrarily deep batching on the left, e.g. use broadcasting.\n",
    "- Inference cost is exponential in treewidth, so try to write models with narrow treewidth.\n",
    "- If you have trouble, ask for help on [forum.pyro.ai](https://forum.pyro.ai)!\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "- [Overview](#Overview)\n",
    "- [Mechanics of enumeration](#Mechanics-of-enumeration)\n",
    "  - [Multiple latent variables](#Multiple-latent-variables)\n",
    "- [Plates and enumeration](#Plates-and-enumeration)\n",
    "- [Time series example](#Time-series-example)\n",
    "  - [How to enumerate more than 25 variables](#How-to-enumerate-more-than-25-variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "\n",
    "pyro.enable_validation()\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"Overview\"></a>\n",
    "\n",
    "Pyro's enumeration strategy encompasses popular algorithms including variable elimination, exact message passing, forward-filter-backward-sample, inside-out, Baum-Welch, and many other special-case algorithms. Aside from enumeration, Pyro implements a number of inference strategies including variational inference ([SVI](http://docs.pyro.ai/en/dev/inference_algos.html)) and monte carlo ([HMC](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.HMC) and [NUTS](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.NUTS)). Enumeration can be used either as a stand-alone strategy, or as a component of other strategies. Thus enumeration allows Pyro to marginalize out discrete latent variables in HMC and SVI models, and to use variational enumeration of discrete variables in SVI guides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanics of enumeration  <a class=\"anchor\" id=\"Mechanics-of-enumeration\"></a>\n",
    "\n",
    "The core idea of enumeration is to interpret discrete [pyro.sample](http://docs.pyro.ai/en/dev/primitives.html#pyro.sample) statements as full enumeration rather than random sampling. Other inference algorithms can then sum out the enumerated values. For example a sample statement might return scalar shape under the standard \"sample\" interpretation (we'll illustrate with trivial model and guide):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 4\n",
      "model z = 4\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print('model z = {}'.format(z))\n",
    "\n",
    "def guide():\n",
    "    z = pyro.sample(\"z\", dist.Categorical(torch.ones(5)))\n",
    "    print('guide z = {}'.format(z))\n",
    "\n",
    "elbo = Trace_ELBO()\n",
    "elbo.loss(model, guide);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However under the enumeration interpretation, the same sample site will return a fully enumerated set of values, based on its distribution's [.enumerate_support()](https://pytorch.org/docs/stable/distributions.html#torch.distributions.distribution.Distribution.enumerate_support) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = tensor([ 0,  1,  2,  3,  4])\n",
      "model z = tensor([ 0,  1,  2,  3,  4])\n"
     ]
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"parallel\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've used \"parallel\" enumeration to enumerate along a new tensor dimension. This is cheap and allows Pyro to parallelize computation, but requires downstream program structure to avoid branching on the value of `z`. To support dynamic program structure, you can instead use \"sequential\" enumeration, which runs the entire model,guide pair once per sample value, but requires running the model multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guide z = 4\n",
      "model z = 4\n",
      "guide z = 3\n",
      "model z = 3\n",
      "guide z = 2\n",
      "model z = 2\n",
      "guide z = 1\n",
      "model z = 1\n",
      "guide z = 0\n",
      "model z = 0\n"
     ]
    }
   ],
   "source": [
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, config_enumerate(guide, \"sequential\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel enumeration is cheaper but more complex than sequential enumeration, so we'll focus the rest of this tutorial on the parallel variant. Note that both forms can be interleaved.\n",
    "\n",
    "### Multiple latent variables <a class=\"anchor\" id=\"Multiple-latent-variables\"></a>\n",
    "\n",
    "We just saw that a single discrete sample site can be enumerated via nonstandard interpretation. A model with a single discrete latent variable is a mixture model. Models with multiple discrete latent variables can be more complex, including HMMs, CRFs, DBNs, and other structured models. In models with multiple discrete latent variables, Pyro enumerates each variable in a different tensor dimension (counting from the right; see [Tensor Shapes Tutorial](http://pyro.ai/examples/tensor_shapes.html)). This allows Pyro to determine the dependency graph among varaibles and then perform cheap exact inference using variable elimination algorithms.\n",
    "\n",
    "To understand enumeration dimension allocation, consider the following model, where here we collapse variables out of the model, rather than enumerate them in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model x.shape = torch.Size([3])\n",
      "model y.shape = torch.Size([3, 1])\n",
      "model z.shape = torch.Size([3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "@config_enumerate(default=\"parallel\")\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(3, 3).exp(), constraint=constraints.simplex)\n",
    "    x = pyro.sample(\"x\", dist.Categorical(p[0]))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(p[x]))\n",
    "    z = pyro.sample(\"z\", dist.Categorical(p[y]))\n",
    "    print('model x.shape = {}'.format(x.shape))\n",
    "    print('model y.shape = {}'.format(y.shape))\n",
    "    print('model z.shape = {}'.format(z.shape))\n",
    "    \n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=0)\n",
    "elbo.loss(model, guide);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plates and enumeration <a class=\"anchor\" id=\"Plates-and-enumeration\"></a>\n",
    "\n",
    "Pyro [plates](http://docs.pyro.ai/en/dev/primitives.html#pyro.plate) express conditional independence among random variables. Pyro's enumeration strategy can take advantage of plates to reduce exponential-cost enumeration of a cartesian product down to a linear-cost enumeration over conditionally independent random variables in lock-step. This is especially important for e.g. minibatched data.\n",
    "\n",
    "To illustrate, consider a gaussian mixture model with shared variance and different mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with 10 data points\n",
      "x.shape = torch.Size([10])\n",
      "Running model with 10 data points\n",
      "x.shape = torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "@config_enumerate(default=\"parallel\")\n",
    "def model(data, num_components=3):\n",
    "    print('Running model with {} data points'.format(len(data)))\n",
    "    p = pyro.sample(\"p\", dist.Dirichlet(0.5 * torch.ones(3)))\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0, num_components))\n",
    "    with pyro.plate(\"components\", num_components):\n",
    "        loc = pyro.sample(\"loc\", dist.Normal(0, 10))\n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        x = pyro.sample(\"x\", dist.Categorical(p))\n",
    "        print(\"x.shape = {}\".format(x.shape))\n",
    "        pyro.sample(\"obs\", dist.Normal(loc[x], scale), obs=data)\n",
    "        \n",
    "guide = AutoDiagonalNormal(poutine.block(model, hide=[\"x\", \"data\"]))\n",
    "\n",
    "data = torch.randn(10)\n",
    "        \n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "elbo.loss(model, guide, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the model is run twice, first by the `AutoDiagonalNormal` to trace sample sites, and second by `elbo` to compute loss. In the first run, `x` has standard interpretation of one sample per datum, hence shape `(10,)`. In the second run enumeration can use the same three values `(3,1)` for all data points, and relies on broadcasting for any dependent sample or observe sites that depend on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series example  <a class=\"anchor\" id=\"Time-series-example\"></a>\n",
    "\n",
    "Consider a discrete HMM with latent states $x_t$ and observations $y_t$. Suppose we want to learn the transition and emission probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 4\n",
    "num_steps = 10\n",
    "data = dist.Categorical(torch.ones(num_steps, data_dim)).sample()\n",
    "\n",
    "def hmm_model(data, data_dim, hidden_dim=10):\n",
    "    print('Running for {} time steps'.format(len(data)))\n",
    "    # Sample global matrices wrt a Jeffreys prior.\n",
    "    with pyro.plate(\"hidden_state\", hidden_dim):\n",
    "        transition = pyro.sample(\"transition\", dist.Dirichlet(0.5 * torch.ones(hidden_dim)))\n",
    "        emission = pyro.sample(\"emission\", dist.Dirichlet(0.5 * torch.ones(data_dim)))\n",
    "\n",
    "    x = 0  # initial state\n",
    "    for t, y in enumerate(data):\n",
    "        x = pyro.sample(\"x_{}\".format(t), dist.Categorical(transition[x]),\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "        pyro.sample(\"y_{}\".format(t), dist.Categorical(emission[x]), obs=y)\n",
    "        print(\"x_{}.shape = {}\".format(t, x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn the global parameters using SVI with an autoguide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 10 time steps\n",
      "x_0.shape = torch.Size([])\n",
      "x_1.shape = torch.Size([])\n",
      "x_2.shape = torch.Size([])\n",
      "x_3.shape = torch.Size([])\n",
      "x_4.shape = torch.Size([])\n",
      "x_5.shape = torch.Size([])\n",
      "x_6.shape = torch.Size([])\n",
      "x_7.shape = torch.Size([])\n",
      "x_8.shape = torch.Size([])\n",
      "x_9.shape = torch.Size([])\n",
      "Running for 10 time steps\n",
      "x_0.shape = torch.Size([10, 1])\n",
      "x_1.shape = torch.Size([10, 1, 1])\n",
      "x_2.shape = torch.Size([10, 1, 1, 1])\n",
      "x_3.shape = torch.Size([10, 1, 1, 1, 1])\n",
      "x_4.shape = torch.Size([10, 1, 1, 1, 1, 1])\n",
      "x_5.shape = torch.Size([10, 1, 1, 1, 1, 1, 1])\n",
      "x_6.shape = torch.Size([10, 1, 1, 1, 1, 1, 1, 1])\n",
      "x_7.shape = torch.Size([10, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "x_8.shape = torch.Size([10, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "x_9.shape = torch.Size([10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "hmm_guide = AutoDiagonalNormal(poutine.block(hmm_model, expose=[\"transition\", \"emission\"]))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "elbo.loss(hmm_model, hmm_guide, data, data_dim=data_dim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model was run twice here: first it was run without enumeration by `AutoDiagonalNormal`, so that the autoguide can record all sample sites; then second it is run by `TraceEnum_ELBO` with enumeration enabled. We see in the first run that samples have standard interpretation, whereas in the second run samples have the enumeration interpretation.\n",
    "\n",
    "For more complex examples, including minibatching and multiple plates, see the [HMM tutorial](https://github.com/uber/pyro/blob/dev/examples/hmm.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to enumerate more than 25 variables <a class=\"anchor\" id=\"How-to-enumerate-more-than-25-variables\"></a>\n",
    "\n",
    "PyTorch tensors have a dimension limit of 25 in CUDA and 64 in CPU. By default Pyro enumerates each sample site in a new dimension. If you need more sample sites, you can annotate your model with  [pyro.markov](http://docs.pyro.ai/en/dev/poutine.html#pyro.poutine.markov) to tell Pyro when it is safe to recycle tensor dimensions. Let's see how that works with the HMM model from above. The only change we need is to annotate the for loop with `pyro.markov`:\n",
    "```diff\n",
    "- for t, y in enumerate(data):\n",
    "+ for t, y in pyro.markov(enumerate(data)):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0.shape = torch.Size([10, 1])\n",
      "x_1.shape = torch.Size([10, 1, 1])\n",
      "x_2.shape = torch.Size([10, 1])\n",
      "x_3.shape = torch.Size([10, 1, 1])\n",
      "x_4.shape = torch.Size([10, 1])\n",
      "x_5.shape = torch.Size([10, 1, 1])\n",
      "x_6.shape = torch.Size([10, 1])\n",
      "x_7.shape = torch.Size([10, 1, 1])\n",
      "x_8.shape = torch.Size([10, 1])\n",
      "x_9.shape = torch.Size([10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def hmm_model(data, data_dim, hidden_dim=10):\n",
    "    with pyro.plate(\"hidden_state\", hidden_dim):\n",
    "        transition = pyro.sample(\"transition\", dist.Dirichlet(0.5 * torch.ones(hidden_dim)))\n",
    "        emission = pyro.sample(\"emission\", dist.Dirichlet(0.5 * torch.ones(data_dim)))\n",
    "\n",
    "    x = 0  # initial state\n",
    "    for t, y in pyro.markov(enumerate(data)):\n",
    "        x = pyro.sample(\"x_{}\".format(t), dist.Categorical(transition[x]),\n",
    "                        infer={\"enumerate\": \"parallel\"})\n",
    "        pyro.sample(\"y_{}\".format(t), dist.Categorical(emission[x]), obs=y)\n",
    "        print(\"x_{}.shape = {}\".format(t, x.shape))\n",
    "\n",
    "# We'll reuse the same guide and elbo.\n",
    "elbo.loss(hmm_model, hmm_guide, data, data_dim=data_dim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this model now only needs three tensor dimensions: one for the plate, one for even states, and one for odd states. For more complex examples, see the Dynamic Bayes Net model in the [HMM example](https://github.com/uber/pyro/blob/dev/examples/hmm.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
