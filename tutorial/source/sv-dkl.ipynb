{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Variational Deep Kernel Learning\n",
    "\n",
    "https://papers.nips.cc/paper/6426-stochastic-variational-deep-kernel-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://github.com/pytorch/examples/tree/master/mnist\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "import pyro.infer as infer\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--num-inducing', type=int, default=70, metavar='N',\n",
    "                    help='number of inducing input (default: 70)')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args(\"--epochs 15 --lr 0.01 --log-interval 100\".split())\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "pyro.set_rng_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = pyro.module(\"CNN\", CNN().double().cuda() if args.cuda else CNN().double())\n",
    "kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn)\n",
    "Xu = next(iter(train_loader))[0][:args.num_inducing]\n",
    "likelihood = gp.likelihoods.MultiClass(num_classes=10)\n",
    "gpmodel = gp.models.SparseVariationalGP(X=Xu, y=None, kernel=kernel, Xu=Xu,\n",
    "                                        likelihood=likelihood, latent_shape=torch.Size([10]),\n",
    "                                        num_data=60000, whiten=False)\n",
    "gpmodel.double()\n",
    "if args.cuda:\n",
    "    gpmodel.cuda()\n",
    "\n",
    "optimizer = optim.Adam({\"lr\": args.lr})\n",
    "\n",
    "svi = infer.SVI(poutine.scale(gpmodel.model, 1/60000), poutine.scale(gpmodel.guide, 1/60000),\n",
    "                optimizer, \"ELBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    gpmodel.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        gpmodel.set_data(data.double(), target)\n",
    "        loss = svi.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {:2d} [{:5d}/{} ({:2.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    gpmodel.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        f_loc, f_var = gpmodel(data.double())\n",
    "        pred = gpmodel.likelihood(f_loc, f_var)\n",
    "        correct += pred.eq(target).long().cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1 [    0/60000 ( 0%)]\tLoss: 387.829002\n",
      "Train Epoch:  1 [ 6400/60000 (11%)]\tLoss: 5.098616\n",
      "Train Epoch:  1 [12800/60000 (21%)]\tLoss: 3.707834\n",
      "Train Epoch:  1 [19200/60000 (32%)]\tLoss: 3.112422\n",
      "Train Epoch:  1 [25600/60000 (43%)]\tLoss: 2.815061\n",
      "Train Epoch:  1 [32000/60000 (53%)]\tLoss: 2.611294\n",
      "Train Epoch:  1 [38400/60000 (64%)]\tLoss: 2.690572\n",
      "Train Epoch:  1 [44800/60000 (75%)]\tLoss: 2.481877\n",
      "Train Epoch:  1 [51200/60000 (85%)]\tLoss: 2.394424\n",
      "Train Epoch:  1 [57600/60000 (96%)]\tLoss: 2.292319\n",
      "\n",
      "Test set: Accuracy: 1234/10000 (12%)\n",
      "\n",
      "Train Epoch:  2 [    0/60000 ( 0%)]\tLoss: 2.318852\n",
      "Train Epoch:  2 [ 6400/60000 (11%)]\tLoss: 2.221023\n",
      "Train Epoch:  2 [12800/60000 (21%)]\tLoss: 2.129875\n",
      "Train Epoch:  2 [19200/60000 (32%)]\tLoss: 2.088607\n",
      "Train Epoch:  2 [25600/60000 (43%)]\tLoss: 2.033068\n",
      "Train Epoch:  2 [32000/60000 (53%)]\tLoss: 2.065601\n",
      "Train Epoch:  2 [38400/60000 (64%)]\tLoss: 1.995911\n",
      "Train Epoch:  2 [44800/60000 (75%)]\tLoss: 1.849222\n",
      "Train Epoch:  2 [51200/60000 (85%)]\tLoss: 1.771148\n",
      "Train Epoch:  2 [57600/60000 (96%)]\tLoss: 1.789419\n",
      "\n",
      "Test set: Accuracy: 2448/10000 (24%)\n",
      "\n",
      "Train Epoch:  3 [    0/60000 ( 0%)]\tLoss: 1.815617\n",
      "Train Epoch:  3 [ 6400/60000 (11%)]\tLoss: 1.681896\n",
      "Train Epoch:  3 [12800/60000 (21%)]\tLoss: 1.538082\n",
      "Train Epoch:  3 [19200/60000 (32%)]\tLoss: 1.540615\n",
      "Train Epoch:  3 [25600/60000 (43%)]\tLoss: 1.599169\n",
      "Train Epoch:  3 [32000/60000 (53%)]\tLoss: 1.699380\n",
      "Train Epoch:  3 [38400/60000 (64%)]\tLoss: 1.490591\n",
      "Train Epoch:  3 [44800/60000 (75%)]\tLoss: 1.431123\n",
      "Train Epoch:  3 [51200/60000 (85%)]\tLoss: 1.477493\n",
      "Train Epoch:  3 [57600/60000 (96%)]\tLoss: 1.499586\n",
      "\n",
      "Test set: Accuracy: 3839/10000 (38%)\n",
      "\n",
      "Train Epoch:  4 [    0/60000 ( 0%)]\tLoss: 1.557813\n",
      "Train Epoch:  4 [ 6400/60000 (11%)]\tLoss: 1.192526\n",
      "Train Epoch:  4 [12800/60000 (21%)]\tLoss: 1.321559\n",
      "Train Epoch:  4 [19200/60000 (32%)]\tLoss: 1.495481\n",
      "Train Epoch:  4 [25600/60000 (43%)]\tLoss: 1.418644\n",
      "Train Epoch:  4 [32000/60000 (53%)]\tLoss: 1.224159\n",
      "Train Epoch:  4 [38400/60000 (64%)]\tLoss: 1.358123\n",
      "Train Epoch:  4 [44800/60000 (75%)]\tLoss: 1.296078\n",
      "Train Epoch:  4 [51200/60000 (85%)]\tLoss: 1.233307\n",
      "Train Epoch:  4 [57600/60000 (96%)]\tLoss: 1.207796\n",
      "\n",
      "Test set: Accuracy: 4467/10000 (44%)\n",
      "\n",
      "Train Epoch:  5 [    0/60000 ( 0%)]\tLoss: 1.260580\n",
      "Train Epoch:  5 [ 6400/60000 (11%)]\tLoss: 1.385822\n",
      "Train Epoch:  5 [12800/60000 (21%)]\tLoss: 1.230824\n",
      "Train Epoch:  5 [19200/60000 (32%)]\tLoss: 1.231466\n",
      "Train Epoch:  5 [25600/60000 (43%)]\tLoss: 1.082364\n",
      "Train Epoch:  5 [32000/60000 (53%)]\tLoss: 1.042831\n",
      "Train Epoch:  5 [38400/60000 (64%)]\tLoss: 0.998757\n",
      "Train Epoch:  5 [44800/60000 (75%)]\tLoss: 1.063301\n",
      "Train Epoch:  5 [51200/60000 (85%)]\tLoss: 1.402053\n",
      "Train Epoch:  5 [57600/60000 (96%)]\tLoss: 1.230615\n",
      "\n",
      "Test set: Accuracy: 4537/10000 (45%)\n",
      "\n",
      "Train Epoch:  6 [    0/60000 ( 0%)]\tLoss: 1.354825\n",
      "Train Epoch:  6 [ 6400/60000 (11%)]\tLoss: 1.206779\n",
      "Train Epoch:  6 [12800/60000 (21%)]\tLoss: 1.193223\n",
      "Train Epoch:  6 [19200/60000 (32%)]\tLoss: 1.145664\n",
      "Train Epoch:  6 [25600/60000 (43%)]\tLoss: 1.028519\n",
      "Train Epoch:  6 [32000/60000 (53%)]\tLoss: 0.941161\n",
      "Train Epoch:  6 [38400/60000 (64%)]\tLoss: 1.197944\n",
      "Train Epoch:  6 [44800/60000 (75%)]\tLoss: 0.971348\n",
      "Train Epoch:  6 [51200/60000 (85%)]\tLoss: 1.080988\n",
      "Train Epoch:  6 [57600/60000 (96%)]\tLoss: 1.117770\n",
      "\n",
      "Test set: Accuracy: 4838/10000 (48%)\n",
      "\n",
      "Train Epoch:  7 [    0/60000 ( 0%)]\tLoss: 1.220410\n",
      "Train Epoch:  7 [ 6400/60000 (11%)]\tLoss: 1.270222\n",
      "Train Epoch:  7 [12800/60000 (21%)]\tLoss: 0.903731\n",
      "Train Epoch:  7 [19200/60000 (32%)]\tLoss: 1.239783\n",
      "Train Epoch:  7 [25600/60000 (43%)]\tLoss: 1.036530\n",
      "Train Epoch:  7 [32000/60000 (53%)]\tLoss: 1.121167\n",
      "Train Epoch:  7 [38400/60000 (64%)]\tLoss: 1.030323\n",
      "Train Epoch:  7 [44800/60000 (75%)]\tLoss: 1.073072\n",
      "Train Epoch:  7 [51200/60000 (85%)]\tLoss: 1.026874\n",
      "Train Epoch:  7 [57600/60000 (96%)]\tLoss: 1.143340\n",
      "\n",
      "Test set: Accuracy: 4879/10000 (48%)\n",
      "\n",
      "Train Epoch:  8 [    0/60000 ( 0%)]\tLoss: 1.409818\n",
      "Train Epoch:  8 [ 6400/60000 (11%)]\tLoss: 1.283652\n",
      "Train Epoch:  8 [12800/60000 (21%)]\tLoss: 1.131313\n",
      "Train Epoch:  8 [19200/60000 (32%)]\tLoss: 1.182200\n",
      "Train Epoch:  8 [25600/60000 (43%)]\tLoss: 1.279386\n",
      "Train Epoch:  8 [32000/60000 (53%)]\tLoss: 0.969365\n",
      "Train Epoch:  8 [38400/60000 (64%)]\tLoss: 1.022046\n",
      "Train Epoch:  8 [44800/60000 (75%)]\tLoss: 1.136974\n",
      "Train Epoch:  8 [51200/60000 (85%)]\tLoss: 1.023432\n",
      "Train Epoch:  8 [57600/60000 (96%)]\tLoss: 0.820563\n",
      "\n",
      "Test set: Accuracy: 4940/10000 (49%)\n",
      "\n",
      "Train Epoch:  9 [    0/60000 ( 0%)]\tLoss: 1.047960\n",
      "Train Epoch:  9 [ 6400/60000 (11%)]\tLoss: 1.177225\n",
      "Train Epoch:  9 [12800/60000 (21%)]\tLoss: 1.107998\n",
      "Train Epoch:  9 [19200/60000 (32%)]\tLoss: 0.993867\n",
      "Train Epoch:  9 [25600/60000 (43%)]\tLoss: 1.247341\n",
      "Train Epoch:  9 [32000/60000 (53%)]\tLoss: 1.188597\n",
      "Train Epoch:  9 [38400/60000 (64%)]\tLoss: 1.069569\n",
      "Train Epoch:  9 [44800/60000 (75%)]\tLoss: 1.299141\n",
      "Train Epoch:  9 [51200/60000 (85%)]\tLoss: 1.081635\n",
      "Train Epoch:  9 [57600/60000 (96%)]\tLoss: 1.011434\n",
      "\n",
      "Test set: Accuracy: 5115/10000 (51%)\n",
      "\n",
      "Train Epoch: 10 [    0/60000 ( 0%)]\tLoss: 0.993024\n",
      "Train Epoch: 10 [ 6400/60000 (11%)]\tLoss: 1.144916\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.334432\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.105005\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.198597\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.109158\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.239907\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.263911\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.248782\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.180725\n",
      "\n",
      "Test set: Accuracy: 5039/10000 (50%)\n",
      "\n",
      "Train Epoch: 11 [    0/60000 ( 0%)]\tLoss: 1.065780\n",
      "Train Epoch: 11 [ 6400/60000 (11%)]\tLoss: 0.853361\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.963164\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 1.071630\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 1.260850\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 1.201568\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 1.126765\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 1.161925\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 1.014513\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 1.421041\n",
      "\n",
      "Test set: Accuracy: 4971/10000 (49%)\n",
      "\n",
      "Train Epoch: 12 [    0/60000 ( 0%)]\tLoss: 1.106996\n",
      "Train Epoch: 12 [ 6400/60000 (11%)]\tLoss: 1.076159\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 1.077766\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.909948\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.245261\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.996713\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 1.083271\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 1.437751\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 1.028660\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 1.238131\n",
      "\n",
      "Test set: Accuracy: 5074/10000 (50%)\n",
      "\n",
      "Train Epoch: 13 [    0/60000 ( 0%)]\tLoss: 1.017649\n",
      "Train Epoch: 13 [ 6400/60000 (11%)]\tLoss: 1.296617\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 1.224661\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 1.172416\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 1.270532\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 1.033796\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 1.428172\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 1.014974\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 1.108292\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.855705\n",
      "\n",
      "Test set: Accuracy: 4894/10000 (48%)\n",
      "\n",
      "Train Epoch: 14 [    0/60000 ( 0%)]\tLoss: 0.986500\n",
      "Train Epoch: 14 [ 6400/60000 (11%)]\tLoss: 1.312115\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.174913\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 1.269490\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 1.079735\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.008368\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 1.169216\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 1.020472\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 1.133515\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.999468\n",
      "\n",
      "Test set: Accuracy: 5091/10000 (50%)\n",
      "\n",
      "Train Epoch: 15 [    0/60000 ( 0%)]\tLoss: 1.021006\n",
      "Train Epoch: 15 [ 6400/60000 (11%)]\tLoss: 1.271395\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 1.023015\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 1.259013\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 1.345547\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 1.235083\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 1.200530\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 1.358926\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.893619\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 1.040173\n",
      "\n",
      "Test set: Accuracy: 5073/10000 (50%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    with torch.no_grad():\n",
    "        test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "cnn = pyro.module(\"CNN\", CNN().double().cuda() if args.cuda else CNN().double())\n",
    "kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn)\n",
    "Xu = next(iter(train_loader))[0][:args.num_inducing]\n",
    "likelihood = gp.likelihoods.MultiClass(num_classes=10)\n",
    "gpmodel = gp.models.SparseVariationalGP(X=Xu, y=None, kernel=kernel, Xu=Xu,\n",
    "                                        likelihood=likelihood, latent_shape=torch.Size([10]),\n",
    "                                        num_data=60000, whiten=True)\n",
    "gpmodel.double()\n",
    "if args.cuda:\n",
    "    gpmodel.cuda()\n",
    "\n",
    "optimizer = optim.Adam({\"lr\": args.lr})\n",
    "\n",
    "svi = infer.SVI(poutine.scale(gpmodel.model, 1/60000), poutine.scale(gpmodel.guide, 1/60000),\n",
    "                optimizer, \"ELBO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1 [    0/60000 ( 0%)]\tLoss: 2.666359\n",
      "Train Epoch:  1 [ 6400/60000 (11%)]\tLoss: 1.595297\n",
      "Train Epoch:  1 [12800/60000 (21%)]\tLoss: 1.202300\n",
      "Train Epoch:  1 [19200/60000 (32%)]\tLoss: 1.240456\n",
      "Train Epoch:  1 [25600/60000 (43%)]\tLoss: 1.080920\n",
      "Train Epoch:  1 [32000/60000 (53%)]\tLoss: 1.149704\n",
      "Train Epoch:  1 [38400/60000 (64%)]\tLoss: 1.299721\n",
      "Train Epoch:  1 [44800/60000 (75%)]\tLoss: 1.494579\n",
      "Train Epoch:  1 [51200/60000 (85%)]\tLoss: 1.085025\n",
      "Train Epoch:  1 [57600/60000 (96%)]\tLoss: 1.114718\n",
      "\n",
      "Test set: Accuracy: 4757/10000 (47%)\n",
      "\n",
      "Train Epoch:  2 [    0/60000 ( 0%)]\tLoss: 1.052407\n",
      "Train Epoch:  2 [ 6400/60000 (11%)]\tLoss: 0.898347\n",
      "Train Epoch:  2 [12800/60000 (21%)]\tLoss: 1.107396\n",
      "Train Epoch:  2 [19200/60000 (32%)]\tLoss: 1.093968\n",
      "Train Epoch:  2 [25600/60000 (43%)]\tLoss: 1.208402\n",
      "Train Epoch:  2 [32000/60000 (53%)]\tLoss: 1.015945\n",
      "Train Epoch:  2 [38400/60000 (64%)]\tLoss: 1.120113\n",
      "Train Epoch:  2 [44800/60000 (75%)]\tLoss: 0.891566\n",
      "Train Epoch:  2 [51200/60000 (85%)]\tLoss: 0.930851\n",
      "Train Epoch:  2 [57600/60000 (96%)]\tLoss: 1.229991\n",
      "\n",
      "Test set: Accuracy: 4991/10000 (49%)\n",
      "\n",
      "Train Epoch:  3 [    0/60000 ( 0%)]\tLoss: 1.006665\n",
      "Train Epoch:  3 [ 6400/60000 (11%)]\tLoss: 1.211381\n",
      "Train Epoch:  3 [12800/60000 (21%)]\tLoss: 1.064960\n",
      "Train Epoch:  3 [19200/60000 (32%)]\tLoss: 1.103462\n",
      "Train Epoch:  3 [25600/60000 (43%)]\tLoss: 1.244422\n",
      "Train Epoch:  3 [32000/60000 (53%)]\tLoss: 1.083331\n",
      "Train Epoch:  3 [38400/60000 (64%)]\tLoss: 0.950262\n",
      "Train Epoch:  3 [44800/60000 (75%)]\tLoss: 1.127272\n",
      "Train Epoch:  3 [51200/60000 (85%)]\tLoss: 1.078027\n",
      "Train Epoch:  3 [57600/60000 (96%)]\tLoss: 1.026392\n",
      "\n",
      "Test set: Accuracy: 5105/10000 (51%)\n",
      "\n",
      "Train Epoch:  4 [    0/60000 ( 0%)]\tLoss: 1.026086\n",
      "Train Epoch:  4 [ 6400/60000 (11%)]\tLoss: 1.024263\n",
      "Train Epoch:  4 [12800/60000 (21%)]\tLoss: 1.099748\n",
      "Train Epoch:  4 [19200/60000 (32%)]\tLoss: 1.189099\n",
      "Train Epoch:  4 [25600/60000 (43%)]\tLoss: 1.079783\n",
      "Train Epoch:  4 [32000/60000 (53%)]\tLoss: 1.066591\n",
      "Train Epoch:  4 [38400/60000 (64%)]\tLoss: 1.006333\n",
      "Train Epoch:  4 [44800/60000 (75%)]\tLoss: 1.030613\n",
      "Train Epoch:  4 [51200/60000 (85%)]\tLoss: 0.866270\n",
      "Train Epoch:  4 [57600/60000 (96%)]\tLoss: 1.095585\n",
      "\n",
      "Test set: Accuracy: 5207/10000 (52%)\n",
      "\n",
      "Train Epoch:  5 [    0/60000 ( 0%)]\tLoss: 1.065620\n",
      "Train Epoch:  5 [ 6400/60000 (11%)]\tLoss: 1.068784\n",
      "Train Epoch:  5 [12800/60000 (21%)]\tLoss: 0.819290\n",
      "Train Epoch:  5 [19200/60000 (32%)]\tLoss: 1.094285\n",
      "Train Epoch:  5 [25600/60000 (43%)]\tLoss: 1.066015\n",
      "Train Epoch:  5 [32000/60000 (53%)]\tLoss: 1.200102\n",
      "Train Epoch:  5 [38400/60000 (64%)]\tLoss: 1.018991\n",
      "Train Epoch:  5 [44800/60000 (75%)]\tLoss: 1.159868\n",
      "Train Epoch:  5 [51200/60000 (85%)]\tLoss: 0.953159\n",
      "Train Epoch:  5 [57600/60000 (96%)]\tLoss: 0.989548\n",
      "\n",
      "Test set: Accuracy: 5253/10000 (52%)\n",
      "\n",
      "Train Epoch:  6 [    0/60000 ( 0%)]\tLoss: 0.853553\n",
      "Train Epoch:  6 [ 6400/60000 (11%)]\tLoss: 1.160726\n",
      "Train Epoch:  6 [12800/60000 (21%)]\tLoss: 0.845274\n",
      "Train Epoch:  6 [19200/60000 (32%)]\tLoss: 1.175792\n",
      "Train Epoch:  6 [25600/60000 (43%)]\tLoss: 1.284169\n",
      "Train Epoch:  6 [32000/60000 (53%)]\tLoss: 0.846734\n",
      "Train Epoch:  6 [38400/60000 (64%)]\tLoss: 0.979329\n",
      "Train Epoch:  6 [44800/60000 (75%)]\tLoss: 1.101640\n",
      "Train Epoch:  6 [51200/60000 (85%)]\tLoss: 1.257596\n",
      "Train Epoch:  6 [57600/60000 (96%)]\tLoss: 1.226072\n",
      "\n",
      "Test set: Accuracy: 5094/10000 (50%)\n",
      "\n",
      "Train Epoch:  7 [    0/60000 ( 0%)]\tLoss: 0.836886\n",
      "Train Epoch:  7 [ 6400/60000 (11%)]\tLoss: 1.173846\n",
      "Train Epoch:  7 [12800/60000 (21%)]\tLoss: 0.975177\n",
      "Train Epoch:  7 [19200/60000 (32%)]\tLoss: 1.342586\n",
      "Train Epoch:  7 [25600/60000 (43%)]\tLoss: 0.913949\n",
      "Train Epoch:  7 [32000/60000 (53%)]\tLoss: 1.030505\n",
      "Train Epoch:  7 [38400/60000 (64%)]\tLoss: 1.048328\n",
      "Train Epoch:  7 [44800/60000 (75%)]\tLoss: 0.890829\n",
      "Train Epoch:  7 [51200/60000 (85%)]\tLoss: 1.119822\n",
      "Train Epoch:  7 [57600/60000 (96%)]\tLoss: 1.108034\n",
      "\n",
      "Test set: Accuracy: 5230/10000 (52%)\n",
      "\n",
      "Train Epoch:  8 [    0/60000 ( 0%)]\tLoss: 1.275694\n",
      "Train Epoch:  8 [ 6400/60000 (11%)]\tLoss: 0.927972\n",
      "Train Epoch:  8 [12800/60000 (21%)]\tLoss: 1.126950\n",
      "Train Epoch:  8 [19200/60000 (32%)]\tLoss: 1.072772\n",
      "Train Epoch:  8 [25600/60000 (43%)]\tLoss: 0.918870\n",
      "Train Epoch:  8 [32000/60000 (53%)]\tLoss: 0.886034\n",
      "Train Epoch:  8 [38400/60000 (64%)]\tLoss: 0.857078\n",
      "Train Epoch:  8 [44800/60000 (75%)]\tLoss: 1.372996\n",
      "Train Epoch:  8 [51200/60000 (85%)]\tLoss: 1.092789\n",
      "Train Epoch:  8 [57600/60000 (96%)]\tLoss: 1.265539\n",
      "\n",
      "Test set: Accuracy: 5243/10000 (52%)\n",
      "\n",
      "Train Epoch:  9 [    0/60000 ( 0%)]\tLoss: 0.847860\n",
      "Train Epoch:  9 [ 6400/60000 (11%)]\tLoss: 0.873874\n",
      "Train Epoch:  9 [12800/60000 (21%)]\tLoss: 1.059565\n",
      "Train Epoch:  9 [19200/60000 (32%)]\tLoss: 0.926399\n",
      "Train Epoch:  9 [25600/60000 (43%)]\tLoss: 1.180898\n",
      "Train Epoch:  9 [32000/60000 (53%)]\tLoss: 1.218838\n",
      "Train Epoch:  9 [38400/60000 (64%)]\tLoss: 0.886050\n",
      "Train Epoch:  9 [44800/60000 (75%)]\tLoss: 0.876958\n",
      "Train Epoch:  9 [51200/60000 (85%)]\tLoss: 1.311281\n",
      "Train Epoch:  9 [57600/60000 (96%)]\tLoss: 1.086156\n",
      "\n",
      "Test set: Accuracy: 5249/10000 (52%)\n",
      "\n",
      "Train Epoch: 10 [    0/60000 ( 0%)]\tLoss: 1.064575\n",
      "Train Epoch: 10 [ 6400/60000 (11%)]\tLoss: 1.190101\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.093562\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.179288\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.336070\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.076109\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.129033\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.086672\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.953348\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 1.025047\n",
      "\n",
      "Test set: Accuracy: 5242/10000 (52%)\n",
      "\n",
      "Train Epoch: 11 [    0/60000 ( 0%)]\tLoss: 1.329256\n",
      "Train Epoch: 11 [ 6400/60000 (11%)]\tLoss: 1.246802\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 1.104613\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 1.228088\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.943173\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.883782\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 1.039427\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 1.070847\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.954206\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 1.030720\n",
      "\n",
      "Test set: Accuracy: 5191/10000 (51%)\n",
      "\n",
      "Train Epoch: 12 [    0/60000 ( 0%)]\tLoss: 1.050550\n",
      "Train Epoch: 12 [ 6400/60000 (11%)]\tLoss: 0.969834\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 1.098908\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 1.218380\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.203347\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 1.040877\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.840095\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 1.349533\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.902761\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 1.040652\n",
      "\n",
      "Test set: Accuracy: 5226/10000 (52%)\n",
      "\n",
      "Train Epoch: 13 [    0/60000 ( 0%)]\tLoss: 0.913689\n",
      "Train Epoch: 13 [ 6400/60000 (11%)]\tLoss: 1.025052\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 1.085832\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.825852\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 1.018199\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.843086\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.912108\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 1.067394\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 1.194810\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.858388\n",
      "\n",
      "Test set: Accuracy: 5250/10000 (52%)\n",
      "\n",
      "Train Epoch: 14 [    0/60000 ( 0%)]\tLoss: 1.042262\n",
      "Train Epoch: 14 [ 6400/60000 (11%)]\tLoss: 1.016504\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.114854\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.926765\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 1.422822\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 1.280174\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.933112\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.818682\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.985718\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.935634\n",
      "\n",
      "Test set: Accuracy: 5228/10000 (52%)\n",
      "\n",
      "Train Epoch: 15 [    0/60000 ( 0%)]\tLoss: 1.146906\n",
      "Train Epoch: 15 [ 6400/60000 (11%)]\tLoss: 1.114761\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 1.110102\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 1.255379\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 1.172556\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 1.189685\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.992796\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 1.156057\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 1.083950\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 1.149780\n",
      "\n",
      "Test set: Accuracy: 5159/10000 (51%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    with torch.no_grad():\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
