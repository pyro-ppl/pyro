{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding MLE and MAP on simple models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyAQ02Dajes3"
   },
   "source": [
    "The example below I use from: https://pyro.ai/examples/svi_part_i.html#A-simple-example\n",
    "\n",
    "We will start with the quote from: https://forum.pyro.ai/t/correct-map-guide-without-using-automatic-guide-generation/940 \n",
    "\n",
    "**\"If you want a MAP estimate for alpha, you need to pyro.sample it from a prior distribution in your model and delta distribution in your guide just like your second guide does with theta, rather than treating it as a constant. If you instead want a maximum likelihood estimate of alpha, you need to wrap it with a pyro.param call in the model and omit it from your guide\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxRoROT_4KzM"
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "# Pyro\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "pyro.enable_validation(True)    # <---- This is always a good idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our data and train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Df8qZqslAoX"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for _ in range(6):\n",
    "    data.append(torch.tensor(1.0))\n",
    "for _ in range(4):\n",
    "    data.append(torch.tensor(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bu232xqk_i5"
   },
   "outputs": [],
   "source": [
    "def train(model, guide,lr=0.005):\n",
    "  # set up the optimizer\n",
    "  adam_params = {\"lr\": lr, \"betas\": (0.90, 0.999)}\n",
    "  optimizer = Adam(adam_params)\n",
    "  pyro.clear_param_store()\n",
    "  # setup the inference algorithm\n",
    "  svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "  n_steps = 5000\n",
    "  # do gradient steps\n",
    "  for step in range(n_steps):\n",
    "      loss = svi.step(torch.tensor(data))\n",
    "      if step % 1000 == 0:\n",
    "          print('%.4f' %(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WSYgrdFjczI"
   },
   "source": [
    "## MLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlny9Usv4PQA"
   },
   "outputs": [],
   "source": [
    "def model_MLE(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.param(\"latent_fairness\", torch.tensor(0.1,requires_grad=False), constraint=constraints.positive)\n",
    "    # loop over the observed data\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # observe datapoint i using the bernoulli\n",
    "        # likelihood Bernoulli(f)\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(f), obs=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5th7WXQm4yGb"
   },
   "outputs": [],
   "source": [
    "def guide_MLE(data):\n",
    "  # mu_map = pyro.param('mu_map', torch.tensor(1.0))\n",
    "  # pyro.sample('theta', dist.Delta(mu_map))\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "rGHOjdlq49K2",
    "outputId": "292e7629-6981-4888-c9b5-59501098f4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2370\n",
      "6.7301\n",
      "6.7301\n",
      "6.7301\n",
      "6.7301\n"
     ]
    }
   ],
   "source": [
    "train(model_MLE,guide_MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wA1OzZ7W5B0T",
    "outputId": "8e84a4b2-3ceb-4381-fd10-179ca0cadb1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5999999642372131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.param('latent_fairness').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ue5i6V_mAth"
   },
   "source": [
    "0.599999 very close to 0.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri9W1zy3kZ0U"
   },
   "source": [
    "### Through Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1B21gVtrmaro"
   },
   "source": [
    "This is nothing special, I copy whole from the tutorial. Prior is Beta(10,10), then the posterior is 0.533333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xbKgIMjR5Tla"
   },
   "outputs": [],
   "source": [
    "def model_posterior(data):\n",
    "    # define the hyperparameters that control the beta prior\n",
    "    alpha0 = torch.tensor(10.0)\n",
    "    beta0 = torch.tensor(10.0)\n",
    "    # sample f from the beta prior\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(alpha0, beta0))\n",
    "    # loop over the observed data\n",
    "    with pyro.plate('data', len(data)):\n",
    "        # observe datapoint i using the bernoulli\n",
    "        # likelihood Bernoulli(f)\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(f), obs=data)\n",
    "\n",
    "def guide_posterior(data):\n",
    "    # register the two variational parameters with Pyro\n",
    "    # - both parameters will have initial value 15.0.\n",
    "    # - because we invoke constraints.positive, the optimizer\n",
    "    # will take gradients on the unconstrained parameters\n",
    "    # (which are related to the constrained parameters by a log)\n",
    "    alpha_q = pyro.param(\"alpha_q\", torch.tensor(15.0),\n",
    "                         constraint=constraints.positive)\n",
    "    beta_q = pyro.param(\"beta_q\", torch.tensor(15.0),\n",
    "                        constraint=constraints.positive)\n",
    "    # sample latent_fairness from the distribution Beta(alpha_q, beta_q)\n",
    "    pyro.sample(\"latent_fairness\", dist.Beta(alpha_q, beta_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "7KVdFepcmpat",
    "outputId": "672b1ab1-6b7d-4507-ea22-be8a2917d070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7590\n",
      "7.0591\n",
      "7.0463\n",
      "7.0819\n",
      "7.0703\n"
     ]
    }
   ],
   "source": [
    "train(model_posterior,guide_posterior,lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XMSsweKNmuIQ",
    "outputId": "bf308721-5984-452e-dfda-4551321b3ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "based on the data and our prior belief, the fairness of the coin is 0.530 +- 0.090\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "\n",
    "# here we use some facts about the beta distribution\n",
    "# compute the inferred mean of the coin's fairness\n",
    "inferred_mean = alpha_q / (alpha_q + beta_q)\n",
    "# compute inferred standard deviation\n",
    "factor = beta_q / (alpha_q * (1.0 + alpha_q + beta_q))\n",
    "inferred_std = inferred_mean * math.sqrt(factor)\n",
    "\n",
    "print(\"\\nbased on the data and our prior belief, the fairness \" +\n",
    "      \"of the coin is %.3f +- %.3f\" % (inferred_mean, inferred_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M98SZEk7vKiD"
   },
   "source": [
    "MAP is the mode of posterior distribution, now or we plot the distribution, or we compute it directly. I choose latter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GVN3oRfFvHz_",
    "outputId": "07165b57-9273-403c-d6ef-2960a80e4c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5318537663134782\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# grab the learned variational parameters\n",
    "alpha_q = pyro.param(\"alpha_q\").item()\n",
    "beta_q = pyro.param(\"beta_q\").item()\n",
    "print((alpha_q-1)/(alpha_q+beta_q-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0lK1EIpnMzJ"
   },
   "source": [
    "### Through using Delta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0jcdExQxta1"
   },
   "source": [
    "When define Delta distribution, don't init it as 1 for Beta, it will jump to NaN or inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAfxFbAxmydO"
   },
   "outputs": [],
   "source": [
    "def model_map(data):\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(1, 1))\n",
    "    with pyro.plate('data', len(data)):\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(f), obs=data)\n",
    "\n",
    "def guide_map(data):\n",
    "    mu_map = pyro.param(\"mu_map\", torch.tensor(0.5),\n",
    "                         constraint=constraints.positive)\n",
    "    return pyro.sample(\"latent_fairness\", dist.Delta(mu_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "jx5UoDLQns53",
    "outputId": "d5c61eab-c983-4a2e-f328-bc44f8bae546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.9315\n",
      "6.7301\n",
      "6.7301\n",
      "6.7301\n",
      "6.7301\n"
     ]
    }
   ],
   "source": [
    "train(model_map,guide_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wzyv0RynzaR"
   },
   "outputs": [],
   "source": [
    "map_final = guide_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kcqhkJbMrBJr",
    "outputId": "51ffc09b-1fe8-49e8-c57f-df5a6f9277e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000, grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bM2Vv_Hnu8xO"
   },
   "source": [
    "Ok beta(1,1) is uniform, then map equal to mle. = 0.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "voqjtLasrFUt"
   },
   "outputs": [],
   "source": [
    "def model_map(data):\n",
    "    f = pyro.sample(\"latent_fairness\", dist.Beta(10, 10))\n",
    "    with pyro.plate('data', len(data)):\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(f), obs=data)\n",
    "\n",
    "def guide_map(data):\n",
    "    mu_map = pyro.param(\"mu_map\", torch.tensor(0.5),\n",
    "                         constraint=constraints.positive)\n",
    "    return pyro.sample(\"latent_fairness\", dist.Delta(mu_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "y_dIkWk8vDdr",
    "outputId": "243fc836-e2a7-4624-a24e-937999e9fbf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6719\n",
      "5.6004\n",
      "5.6004\n",
      "5.6004\n",
      "5.6004\n"
     ]
    }
   ],
   "source": [
    "train(model_map,guide_map)\n",
    "map_final = guide_map(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g8qOA4HWvHOz",
    "outputId": "193ccd8b-c3b4-4fd3-c565-b45e9f2610bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5357, grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jc6BLZZWhPSc"
   },
   "source": [
    "MAP of Beta(10,10) is same as above, great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOrdNvhMwIgk"
   },
   "source": [
    "What is the real MAP if we compute using our knowledge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o1m-8tkOvzj6",
    "outputId": "08a027d5-f939-4270-ebac-1e3b5711a9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357142857142857\n"
     ]
    }
   ],
   "source": [
    "new_alpha = 10 + 6\n",
    "new_beta = 10 + 4\n",
    "print((new_alpha-1)/(new_alpha+new_beta-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGgG5oI2xRyf"
   },
   "source": [
    "You see, using Delta this time is more accurate than compute whole posterios distribution. Very accurate indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aRtXhjVnw8fo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pyro-3-kind-finding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
