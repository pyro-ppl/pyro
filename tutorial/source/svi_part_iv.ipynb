{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI Part IV: Tips and Tricks\n",
    "\n",
    "The three SVI tutorials leading up to this one ([Part I](http://pyro.ai/examples/svi_part_i.html), [Part II](http://pyro.ai/examples/svi_part_ii.html), & [Part III](http://pyro.ai/examples/svi_part_iii.html)) go through\n",
    "the various steps involved in using Pyro to do variational\n",
    "inference.\n",
    "Along the way we defined models and guides (i.e.~variational distributions),\n",
    "setup variational objectives (in particular [ELBOs](https://docs.pyro.ai/en/dev/inference_algos.html?highlight=elbo#module-pyro.infer.elbo)), \n",
    "and constructed optimizers ([pyro.optim](http://docs.pyro.ai/en/dev/optimization.html)). \n",
    "The effect of all this machinery is to cast Bayesian inference as a *stochastic optimization problem*. \n",
    "This is all very useful, but in order to arrive at our ultimate goal---learning model parameters, inferring approximate posteriors, making predictions with the posterior predictive distribution, etc.---we need to successfully solve this optimization problem. \n",
    "Depending on the particular problem---for example the dimensionality of the latent spaces, whether we have discrete latent variables, and so on---this can be easy or hard. \n",
    "In this tutorial we cover a few tips and tricks we expect to be generally useful for users doing variational inference in Pyro. ELBO not converging? Running into NaNs? Look below for possible solutions!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start with small learning rates\n",
    "\n",
    "While large learning rates might be appropriate for some problems, it's usually good practice to start with small learning rates like $10^{-3}$\n",
    "or $10^{-4}$:\n",
    "```python\n",
    "optimizer = pyro.optim.Adam({\"lr\": 0.001})\n",
    "```\n",
    "This is because ELBO gradients are *stochastic*, and potentially high variance, so large learning rates can quickly lead to parts of model/guide parameter space that are numerically unstable or otherwise undesirable.\n",
    "You can try a larger learning rate once you have achieved stable\n",
    "ELBO optimization using a smaller learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make sure your model and guide distributions have the same support\n",
    "\n",
    "Suppose you have a distribution in your `model` with constrained support, e.g. a LogNormal distribution, which has support on the positive real axis:\n",
    "```python\n",
    "def model():\n",
    "    pyro.sample(\"x\", dist.LogNormal(0.0, 1.0))\n",
    "``` \n",
    "Then you need to ensure that the accompanying `sample` site in the `guide` has the same support:\n",
    "```python\n",
    "def good_guide():\n",
    "    loc = pyro.param(\"loc\", torch.tensor(0.0))\n",
    "    pyro.sample(\"x\", dist.LogNormal(loc, 1.0))\n",
    "``` \n",
    "If you fail to do this and use for example the following inadmissable guide:\n",
    "```python\n",
    "def bad_guide():\n",
    "    loc = pyro.param(\"loc\", torch.tensor(0.0))\n",
    "    pyro.sample(\"x\", dist.Normal(loc, 1.0))\n",
    "```\n",
    "you will likely run into NaNs very quickly. This is because the `log_prob` of a LogNormal distributions evaluated at a sample `x` that satisfies `x<0` is undefined, and the `bad_guide` is likely to produce such samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
